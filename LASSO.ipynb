{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./CLEAN_ABCD_5.1_panel_20240917.csv\", low_memory=False, index_col=0)\n",
    "sample = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize puberty data\n",
    "sample['puberty_k'] = sample[['female_puberty', 'male_puberty']].apply(lambda x: x.iloc[0] if pd.notna(x.iloc[0]) else x.iloc[1], axis=1)\n",
    "tp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also need to decide on cv methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within Categories (Full Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, l in vars.within_categories:\n",
    "  all_predictors = [\"depress_D_p\", \"time\"] + l\n",
    "  all_x = sample[all_predictors]\n",
    "\n",
    "  # Filter the data for the current time point (tp)\n",
    "  t = all_x[all_x['time'] == tp]\n",
    "  t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "  \n",
    "  # Impute missing values using the mean\n",
    "  imputer = SimpleImputer(strategy='mean')\n",
    "  imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "  # Standardize the data\n",
    "  scaler = StandardScaler()\n",
    "  imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "  # Prepare X and y for the model\n",
    "  X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "  y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "  # Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "  model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "  model.fit(X, y)\n",
    "\n",
    "  # print(name)\n",
    "  # print(pd.Series(model.coef_, index=X.columns))\n",
    "\n",
    "  vars.save_plot(model, name, X, y, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across Categories (Full Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictors = [\"depress_D_p\", \"time\"] + vars.across_categories\n",
    "all_x = sample[all_predictors]\n",
    "\n",
    "# Filter the data for the current time point (tp)\n",
    "t = all_x[all_x['time'] == tp]\n",
    "t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "\n",
    "# Impute missing values using the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "# Prepare X and y for the model\n",
    "X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "# Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "vars.save_plot(model, \"across categories\", X, y, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 2075\n"
     ]
    }
   ],
   "source": [
    "low_ale_sample = sample[sample['low_ale_children_p']]\n",
    "print(f\"sample size: {low_ale_sample['subject'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within categories\n",
    "\n",
    "for name, l in vars.within_categories:\n",
    "  all_predictors = [\"depress_D_p\", \"time\"] + l\n",
    "  all_x = low_ale_sample[all_predictors]\n",
    "\n",
    "  # Filter the data for the current time point (tp)\n",
    "  t = all_x[all_x['time'] == tp]\n",
    "  t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "  \n",
    "  # Impute missing values using the mean\n",
    "  imputer = SimpleImputer(strategy='mean')\n",
    "  imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "  # Standardize the data\n",
    "  scaler = StandardScaler()\n",
    "  imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "  # Prepare X and y for the model\n",
    "  X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "  y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "  # Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "  model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "  model.fit(X, y)\n",
    "\n",
    "  # print(name)\n",
    "  # print(pd.Series(model.coef_, index=X.columns))\n",
    "\n",
    "  vars.save_plot(model, \"low ale \" + name, X, y, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# across\n",
    "\n",
    "all_predictors = [\"depress_D_p\", \"time\"] + vars.across_categories\n",
    "all_x = low_ale_sample[all_predictors]\n",
    "\n",
    "# Filter the data for the current time point (tp)\n",
    "t = all_x[all_x['time'] == tp]\n",
    "t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "\n",
    "# Impute missing values using the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "# Prepare X and y for the model\n",
    "X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "# Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "vars.save_plot(model, \"low ale across categories\", X, y, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 2882\n"
     ]
    }
   ],
   "source": [
    "high_ale_sample = sample[sample['high_ale']]\n",
    "print(f\"sample size: {high_ale_sample['subject'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within categories\n",
    "\n",
    "for name, l in vars.within_categories:\n",
    "  all_predictors = [\"depress_D_p\", \"time\"] + l\n",
    "  all_x = high_ale_sample[all_predictors]\n",
    "\n",
    "  # Filter the data for the current time point (tp)\n",
    "  t = all_x[all_x['time'] == tp]\n",
    "  t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "  \n",
    "  # Impute missing values using the mean\n",
    "  imputer = SimpleImputer(strategy='mean')\n",
    "  imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "  # Standardize the data\n",
    "  scaler = StandardScaler()\n",
    "  imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "  # Prepare X and y for the model\n",
    "  X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "  y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "  # Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "  model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "  model.fit(X, y)\n",
    "\n",
    "  # print(name)\n",
    "  # print(pd.Series(model.coef_, index=X.columns))\n",
    "\n",
    "  vars.save_plot(model, \"high ale \" + name, X, y, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# across\n",
    "\n",
    "all_predictors = [\"depress_D_p\", \"time\"] + vars.across_categories\n",
    "all_x = high_ale_sample[all_predictors]\n",
    "\n",
    "# Filter the data for the current time point (tp)\n",
    "t = all_x[all_x['time'] == tp]\n",
    "t_available = t.dropna(axis=1, how='all')  # Keep columns with at least some non-NaN values\n",
    "\n",
    "# Impute missing values using the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed = pd.DataFrame(imputer.fit_transform(t_available), columns=t_available.columns)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "imputed_scaled = pd.DataFrame(scaler.fit_transform(imputed), columns=imputed.columns)\n",
    "\n",
    "# Prepare X and y for the model\n",
    "X = imputed_scaled.drop(columns=[\"depress_D_p\", \"time\"])\n",
    "y = imputed_scaled[\"depress_D_p\"]\n",
    "\n",
    "# Fit LASSO model (ElasticNet with l1_ratio=1 corresponds to LASSO)\n",
    "model = ElasticNetCV(l1_ratio=1, cv=15, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "vars.save_plot(model, \"high ale across categories\", X, y, tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
